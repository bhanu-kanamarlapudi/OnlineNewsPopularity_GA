{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8551cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4dc7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"OnlineNewsPopularity.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579650a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().any()\n",
    "data.drop(columns='url',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8b9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular(shares):\n",
    "    sum = 0\n",
    "    popular_list = []\n",
    "    for i in shares:\n",
    "        sum+=i\n",
    "    avg = sum/len(shares)\n",
    "    for i in shares:\n",
    "        if i >= avg:\n",
    "            popular_list.append(True)\n",
    "        else:\n",
    "            popular_list.append(False)\n",
    "    return popular_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c538efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shares = data[' shares']\n",
    "popularity = popular(shares)\n",
    "data['Popularity'] = popularity\n",
    "col = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f49f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr = data.corr(method=\"pearson\")['Popularity'][:-1]\n",
    "kendall_corr = data.corr(method=\"kendall\")['Popularity'][:-1]\n",
    "spearman_corr = data.corr(method=\"spearman\")[\"Popularity\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c2c430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' n_tokens_title',\n",
       " ' num_self_hrefs',\n",
       " ' num_imgs',\n",
       " ' num_videos',\n",
       " ' average_token_length',\n",
       " ' data_channel_is_lifestyle',\n",
       " ' data_channel_is_entertainment',\n",
       " ' data_channel_is_tech',\n",
       " ' data_channel_is_world',\n",
       " ' kw_max_min',\n",
       " ' kw_avg_min',\n",
       " ' kw_min_max',\n",
       " ' kw_max_max',\n",
       " ' kw_min_avg',\n",
       " ' kw_max_avg',\n",
       " ' kw_avg_avg',\n",
       " ' self_reference_min_shares',\n",
       " ' self_reference_max_shares',\n",
       " ' self_reference_avg_sharess',\n",
       " ' weekday_is_monday',\n",
       " ' weekday_is_sunday',\n",
       " ' is_weekend',\n",
       " ' LDA_00',\n",
       " ' LDA_04',\n",
       " ' global_sentiment_polarity',\n",
       " ' global_rate_positive_words',\n",
       " ' global_rate_negative_words',\n",
       " ' rate_positive_words',\n",
       " ' min_positive_polarity',\n",
       " ' avg_negative_polarity',\n",
       " ' title_sentiment_polarity',\n",
       " ' abs_title_subjectivity',\n",
       " ' shares']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows,ncols = data.shape\n",
    "attr_selection = [] \n",
    "for i in range(ncols-2):\n",
    "    if pearson_corr[i] > 0 and spearman_corr[i] > 0 and kendall_corr[i] > 0:\n",
    "        attr_selection.append(data.columns[i+1])\n",
    "attr_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f00d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>...</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217792</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_tokens_title   num_self_hrefs   num_imgs   num_videos  \\\n",
       "0             12.0              2.0        1.0          0.0   \n",
       "1              9.0              1.0        1.0          0.0   \n",
       "2              9.0              1.0        1.0          0.0   \n",
       "3              9.0              0.0        1.0          0.0   \n",
       "4             13.0             19.0       20.0          0.0   \n",
       "\n",
       "    average_token_length   data_channel_is_lifestyle  \\\n",
       "0               4.680365                         0.0   \n",
       "1               4.913725                         0.0   \n",
       "2               4.393365                         0.0   \n",
       "3               4.404896                         0.0   \n",
       "4               4.682836                         0.0   \n",
       "\n",
       "    data_channel_is_entertainment   data_channel_is_tech  \\\n",
       "0                             1.0                    0.0   \n",
       "1                             0.0                    0.0   \n",
       "2                             0.0                    0.0   \n",
       "3                             1.0                    0.0   \n",
       "4                             0.0                    1.0   \n",
       "\n",
       "    data_channel_is_world   kw_max_min  ...    LDA_00    LDA_04  \\\n",
       "0                     0.0          0.0  ...  0.500331  0.040123   \n",
       "1                     0.0          0.0  ...  0.799756  0.050001   \n",
       "2                     0.0          0.0  ...  0.217792  0.682188   \n",
       "3                     0.0          0.0  ...  0.028573  0.028572   \n",
       "4                     0.0          0.0  ...  0.028633  0.885427   \n",
       "\n",
       "    global_sentiment_polarity   global_rate_positive_words  \\\n",
       "0                    0.092562                     0.045662   \n",
       "1                    0.148948                     0.043137   \n",
       "2                    0.323333                     0.056872   \n",
       "3                    0.100705                     0.041431   \n",
       "4                    0.281003                     0.074627   \n",
       "\n",
       "    global_rate_negative_words   rate_positive_words   min_positive_polarity  \\\n",
       "0                     0.013699              0.769231                0.100000   \n",
       "1                     0.015686              0.733333                0.033333   \n",
       "2                     0.009479              0.857143                0.100000   \n",
       "3                     0.020716              0.666667                0.136364   \n",
       "4                     0.012127              0.860215                0.033333   \n",
       "\n",
       "    avg_negative_polarity   title_sentiment_polarity   abs_title_subjectivity  \n",
       "0               -0.350000                  -0.187500                 0.000000  \n",
       "1               -0.118750                   0.000000                 0.500000  \n",
       "2               -0.466667                   0.000000                 0.500000  \n",
       "3               -0.369697                   0.000000                 0.500000  \n",
       "4               -0.220192                   0.136364                 0.045455  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[' shares'] = (data[' shares'] > 1400 ).astype(int)\n",
    "X = data[attr_selection]\n",
    "X = X.drop(columns=' shares')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a245d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name:  shares, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[' shares']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24400702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import statistics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba7fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_population(p_size, c, top_num):\n",
    "    population = []\n",
    "    for i in range(p_size):\n",
    "        individual = [0]*c\n",
    "        j = 0\n",
    "        while(j<top_num):\n",
    "            p = random.uniform(0,1)\n",
    "            pos = random.randrange(c)\n",
    "            if p >= 0.5 and individual[pos] == 0:\n",
    "                individual[pos] = 1\n",
    "                j = j+1\n",
    "        if sum(individual) == 0:\n",
    "            pos = random.randrange(c)\n",
    "            individual[pos] = 1\n",
    "        population.append(individual)\n",
    "    #print(\"Population is \", population)\n",
    "    #print(population)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911493b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(features, target):\n",
    "    model = MLPClassifier()\n",
    "    scores = cross_val_score(model, features, target, scoring='f1_macro',n_jobs=-1,cv=10)\n",
    "    #print(scores)\n",
    "    #print(scores.mean())\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235b13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness(population, data, target):\n",
    "    fit_values = []\n",
    "    for individual in population:\n",
    "        #print(\"Individual is \",individual)\n",
    "        df = data\n",
    "        i=0\n",
    "        for column in data:\n",
    "            if individual[i] == 0:\n",
    "                df = df.drop(column, axis=1)\n",
    "            i = i+1\n",
    "        features = df\n",
    "        #print(features)\n",
    "        individual_fitness = calculate_fitness(features, target)\n",
    "        fit_values.append(individual_fitness)\n",
    "    return fit_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc20a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(population, fit_values):\n",
    "    parents = []\n",
    "    total = sum(fit_values)\n",
    "    #print(total)\n",
    "    norm_fit_values = [x/total for x in fit_values]\n",
    "    #print(norm_fit_values)\n",
    "    cumulative_fitness = []\n",
    "    i = 0\n",
    "    for norm in norm_fit_values:\n",
    "        i += norm\n",
    "        cumulative_fitness.append(norm)\n",
    "    #print(cumulative_fitness)\n",
    "    p_size = len(population)\n",
    "    #print(p_size)\n",
    "    for count in range(p_size):\n",
    "        random_num = random.uniform(0,1)\n",
    "        individual_num = 0\n",
    "        for score in cumulative_fitness:\n",
    "            if random_num <= score:\n",
    "                parents.append(population[individual_num])\n",
    "                break\n",
    "            individual_num+=1\n",
    "    #print(parents)\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "227b63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parents, probability):\n",
    "    random.shuffle(parents)\n",
    "    num_of_pairs = round(len(parents)*probability/2)\n",
    "    #print(num_of_pairs)\n",
    "    chromosome_len = len(parents[0])\n",
    "    crossover_population = []\n",
    "    for i in range(num_of_pairs):\n",
    "        length = len(parents)\n",
    "        parent1_index = random.randrange(length)\n",
    "        parent2_index = random.randrange(length)\n",
    "        while(parent1_index == parent2_index):\n",
    "            parent2_index = random.randrange(length)\n",
    "        start = random.randrange(chromosome_len)\n",
    "        end = random.randrange(chromosome_len)\n",
    "        if start > end:\n",
    "            start,end = end, start\n",
    "        parent1 = parents[parent1_index]\n",
    "        parent2 = parents[parent2_index]\n",
    "        child1 =  parent1[0:start] \n",
    "        child1.extend(parent2[start:end])\n",
    "        child1.extend(parent1[end:])\n",
    "        child2 =  parent2[0:start]\n",
    "        child2.extend(parent1[start:end])\n",
    "        child2.extend(parent2[end:])\n",
    "        parents.remove(parent1)\n",
    "        parents.remove(parent2)\n",
    "        crossover_population.append(child1)\n",
    "        crossover_population.append(child2)\n",
    "    if (len(parents) > 0):\n",
    "        for remaining_parents in parents:\n",
    "            crossover_population.append(remaining_parents)\n",
    "    return crossover_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5166f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(crossover_population):\n",
    "    for individual in crossover_population:\n",
    "        i_1 = random.randrange(len(individual))\n",
    "        i_2 = random.randrange(len(individual))\n",
    "        while (i_2 == i_1) and individual[i_1] != individual[i_2]:\n",
    "            i_2 = random.randrange(len(individual))\n",
    "        t = individual[i_1]\n",
    "        individual[i_1] = individual[i_2]\n",
    "        individual[i_2] = t\n",
    "    return crossover_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ad06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algo(data,features,target,population_size,tol_level,top_number):\n",
    "    c = data.shape[1]\n",
    "    population = init_population(population_size, c, top_number)\n",
    "    fitness_values = get_fitness(population, data, target)\n",
    "    parents = select_parents(population, fitness_values)\n",
    "    #print(parents)\n",
    "    crossover_population = crossover(parents, 0.8)\n",
    "    population = crossover_population\n",
    "    p = random.uniform(0,1)\n",
    "    if (p <= 0.001):\n",
    "        mutated_population = mutation(crossover_population)\n",
    "        population = mutated_population\n",
    "    fitness_values = get_fitness(population, data, target)\n",
    "    var_of_population = np.var(fitness_values)\n",
    "    #print(\"Variance is \", var_of_population)\n",
    "    count_of_gen = 1\n",
    "    while(var_of_population > tol_level):\n",
    "        print('Generations: ', count_of_gen)\n",
    "        parents = select_parents(population, fitness_values)\n",
    "        crossover_population = crossover(parents, 0.8)\n",
    "        population = crossover_population\n",
    "        p = random.uniform(0,1)\n",
    "        if (p <= 0.001):\n",
    "            mutated_population = mutation(crossover_population)\n",
    "            population = mutated_population\n",
    "        fitness_values = get_fitness(population, data, target)\n",
    "        var_of_population = np.var(fitness_values)\n",
    "        #print(\"Variance is \", var_of_population)\n",
    "        count_of_gen+=1\n",
    "    best_features = []\n",
    "    best_f1_score = 0\n",
    "    optimal_fitness = sum(fitness_values)/ len(fitness_values)\n",
    "    print(\"Average fitness is: \", optimal_fitness)\n",
    "    for i,fit_value in enumerate(fitness_values):\n",
    "        err = abs((fit_value - optimal_fitness)/optimal_fitness)\n",
    "        if err <= 0.01:\n",
    "            best_features = population[i]\n",
    "            best_f1_score = fitness_values\n",
    "    print(best_features)\n",
    "    return best_features,best_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63083c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.436434090429637\n",
      "0.43227007537656964\n",
      "0.44707101265874805\n",
      "0.39076230968971293\n",
      "0.5442987694794518\n",
      "0.38310782338111027\n",
      "0.4241705865456512\n",
      "0.4099556429775548\n",
      "0.5231011512597057\n",
      "0.43038635800373265\n",
      "0.4847494048771921\n",
      "0.43855393627866307\n",
      "0.38361128819819246\n",
      "0.41399469669948796\n",
      "0.5222670475850478\n",
      "0.502138065632829\n",
      "0.41395008100300873\n",
      "0.4094057641280056\n",
      "0.4731253237322939\n",
      "0.4771456559609816\n",
      "0.3855221878193918\n",
      "0.4288107198728398\n",
      "0.378699481245144\n",
      "0.4783556494991384\n",
      "Generations:  1\n",
      "0.4987895059339742\n",
      "0.5361748167430239\n",
      "0.4232406182497428\n",
      "Generations:  2\n",
      "0.5459182346421575\n",
      "0.4996196132849514\n",
      "Generations:  3\n",
      "0.5495793801392604\n",
      "0.48035734402602975\n",
      "Generations:  4\n",
      "0.5112642511538608\n",
      "Average fitness is:  0.5112642511538608\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "top_features, best_f1_score = genetic_algo(X,X,y,20, 0.000005, 25)\n",
    "i = 0\n",
    "list_of_features = []\n",
    "for i in range(len(top_features)):\n",
    "    if(top_features[i]==1):\n",
    "        list_of_features.append(X.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b78bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "[' n_tokens_title', ' num_self_hrefs', ' num_imgs', ' num_videos', ' average_token_length', ' data_channel_is_entertainment', ' data_channel_is_tech', ' data_channel_is_world', ' kw_max_min', ' kw_avg_min', ' kw_min_max', ' kw_min_avg', ' kw_max_avg', ' kw_avg_avg', ' self_reference_max_shares', ' weekday_is_monday', ' weekday_is_sunday', ' LDA_00', ' LDA_04', ' global_sentiment_polarity', ' global_rate_positive_words', ' global_rate_negative_words', ' title_sentiment_polarity', ' abs_title_subjectivity']\n",
      "[0.5112642511538608]\n"
     ]
    }
   ],
   "source": [
    "print(top_features)\n",
    "print(list_of_features)\n",
    "print(best_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88e9e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
